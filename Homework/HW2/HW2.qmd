---
title: "STAT 30040 Homework 2, Exercises 1 & 4"
author: "Robert Winter"
format: pdf
editor: visual

highlight-style: pygments
geometry:
      - top=30mm
      - left=30mm
toc: true
toc-title: Table of Contents
number-sections: true

# Wrap code chunk text
include-in-header:
  text: |
    \usepackage{fvextra}
    \DefineVerbatimEnvironment{Highlighting}{Verbatim}{breaklines,commandchars=\\\{\}}
---

```{r}
#| warning: false
#| echo: false
#| output: false
library(dplyr)
library(ggplot2)
```

# Exercise 1: Binomial Probability Approximations

## Introduction

**Suppose** $X \sim \mathrm{Bin}(n,p)$**. We are interested in the probability** $\mathrm{P}(X=k)$ **for:**

-   **Case 1:** $k=3, \; n=6, \; p=0.3$**;**

-   **Case 2:** $k=11, \; n=40, \; p=0.4$**; and**

-   **Case 3:** $k=2, \; n=400, \; p = 0.003$**;**

**as listed in the table below. In each case, compute:**

-   **the exact binomial probability,**

-   **an approximation using the normal distribution for binomial (with continuity correction), and**

-   **an approximation using the Poisson distribution.**

## Part (a): Computations

**Calculate and show the values of the probabilities in the 3-by-3 table below.**

```{r}
#| echo: false

# Case 1
k = 3
n = 6
p = 0.3

# Exact Binomial
case1bin = dbinom(k, n, p)

# Normal approximation
case1norm = pnorm((k + 0.5 - n*p)/sqrt(n*p*(1-p))) -
            pnorm((k - 0.5 - n*p)/sqrt(n*p*(1-p)))

# Poisson approximation
case1pois = dpois(k, n*p)
```

```{r}
#| echo: false

# Case 2
k = 11
n = 40
p = 0.4

# Exact Binomial
case2bin = dbinom(k, n, p)

# Normal approximation
case2norm = pnorm((k + 0.5 - n*p)/sqrt(n*p*(1-p))) -
            pnorm((k - 0.5 - n*p)/sqrt(n*p*(1-p)))

# Poisson approximation
case2pois = dpois(k, n*p)
```

```{r}
#| echo: false

# Case 3
k = 2
n = 400
p = 0.003

# Exact Binomial
case3bin = dbinom(k, n, p)

# Normal approximation
case3norm = pnorm((k + 0.5 - n*p)/sqrt(n*p*(1-p))) -
            pnorm((k - 0.5 - n*p)/sqrt(n*p*(1-p)))

# Poisson approximation
case3pois = dpois(k, n*p)
```

|                             | Binomial Probability (exact) | Normal Approximation (with continuity correction) |  Poisson Approximation  |
|--------------------------|:---------------:|:---------------:|:---------------:|
| $k=3, \; n=6, \; p=0.3$     |    `r round(case1bin, 4)`    |              `r round(case1norm, 4)`              | `r round(case1pois, 4)` |
| $k=11, \; n=40, \; p = 0.4$ |    `r round(case2bin, 4)`    |              `r round(case2norm, 4)`              | `r round(case2pois, 4)` |
| $k=2, \; n=400, \; p=0.003$ |    `r round(case3bin, 4)`    |              `r round(case3norm, 4)`              | `r round(case3pois, 4)` |

## Part (b): Formulas

**Provide the three formulas of the calculations you used in Part (a).**

We calculate the exact probabilities using the PMF of the binomial distribution:

$$
\mathrm{P}(X=k)={n \choose k}p^k (1-p)^{n-k}.
$$

We approximate the binomial probabilities using the Central Limit Theorem and the normal distribution, with continuity correction, according to the following formula:

$$
\mathrm{P}(X=k) \approx \Phi\Biggl(\frac{k+0.5-np}{\sqrt{np(1-p)}}\Biggr) - \Phi\Biggl(\frac{k-0.5-np}{\sqrt{np(1-p)}}\Biggr).
$$

Finally—in recognition of the fact that if $X_n \sim \mathrm{Bin}(n,p_n)$ with $np_n \rightarrow \lambda$ as $n \rightarrow \infty$, then $X_n \rightarrow_{\mathscr{D}} X \sim \mathrm{Pois}(\lambda)$ as $n \rightarrow \infty$—we approximate the binomial probabilities using the PMF of the Poisson distribution with rate parameter $\lambda = np$:

$$
\mathrm{P}(X=k) \approx \frac{(np)^k e^{-np}}{k!}.
$$

## Part (c): On Approximation Accuracy

**Consider the following scenario: You are asked to approximate the binomial probability (which is too hard to calculate for some reason) in each of the two scenarios below by either normal approximations (with continuity correction) or Poisson approximation.**

1.  **Scenario (i): Approximate** $\mathrm{P}(X=10)$ **when** $X \sim \mathrm{Bin}\big(30, \frac{1}{3}\big)$**.**

2.  **Scenario (ii): Approximate** $\mathrm{P}(X=3)$ **when** $X \sim \mathrm{Bin}\big(500, \frac{1}{1000}\big)$**.**

**Which approximation method would you use? Your reason (in terms of sizes and relations of** $n$**,** $p$**, and** $k$**)? Your answer for this question need only be based on the approximation results in Part (a); no calculations are needed.**

1.  Under Scenario (i), I would prefer to use a normal approximation (with continuity correction) for $\mathrm{P}(X=10)$. Note that this scenario closely resembles the second row ("Case 2") of the table in Part (a): both have a moderate number of trials ($n=40$ above; $n=30$ here), a modest probability of success ($p=0.4$ above; $p=\frac{1}{3}$ here), and a modest number whose density we are approximating ($k=11$ above; $k=10$ here). In Case 2 of the table, the normal approximation was significantly closer to the true binomial probability than the Poisson approximation; we would therefore expect the same in this Scenario (i).

2.  Under Scenario (ii), I would prefer to use a Poisson approximation for $\mathrm{P}(X=10)$. Note that this scenario closely resembles the third row ("Case 3") of the table in Part (a): both have a large number of trials ($n=400$ above; $n=500$ here), a small probability of success ($p=0.003$ above; $p=\frac{1}{1000}$ here), and a small number whose density we are approximating ($k=2$ above; $k=3$ here). In Case 3 of the table, the Poisson approximation was significantly closer to the true binomial probability than the normal approximation; we would therefore expect the same in this Scenario (ii).

In general, since the binomial distribution converges in distribution to the Poisson distribution as $n \rightarrow \infty$ (so long as $n \times p_n$ converges to a number), we would expect the Poisson approximation to do very well for large numbers of trials, like the $n=500$ trials in Scenario (ii). In Scenario (i), with only $n=30$ trials, $n$ is not yet large enough for the Poisson approximation to be very good. However, $n=30$ is (conventionally) just large enough for the Central Limit Theorem to be useful, making the normal approximation perform relatively better in Scenario (i).

# Exercise 4: Coverage Probabilities of Binomial Asymptotic Confidence Intervals

## Introduction

**In this problem, we explore coverage probabilities of binomial asymptotic confidence intervals.**

## Part (a): Small Sample Size

**Generate** $k=100$ **draws of iid random variables from** $\mathrm{Bin}(n,p)$ **for** $n=30$**,** $p=0.1$**. For each draw, obtain the MLE** $\hat{p}=\frac{1}{n}\sum_{i=1}^n X_i$ **and use the test level** $\alpha = 0.05$ **to compute:**

-   **The Wald confidence interval for** $p$ **(with endpoints** $\hat{p} \pm z_{\alpha/2}\sqrt{\frac{1}{n}\hat{p}(1-\hat{p})}$**),**

-   **The Wilson confidence interval for** $p$ **(with endpoints** $\frac{z_{\alpha/2}^2 + 2n\hat{p} \pm z_{\alpha/2}\sqrt{z_{\alpha/2}^2 + 4n\hat{p}(1-\hat{p})}}{2(n+z_{\alpha/2}^2)}$**, and**

-   **The arcsine (converted) confidence interval for** $p$ **you derived in Exercise 3 (using the variation stabilization method).**

**In your simulation,**

i.  **What is the theoretical coverage probability, that is, the theoretical expected proportion of the** $k$ **confidence intervals that should contain the true parameter** $p=0.1$**?**

ii. **For each type of confidence interval, find the proportion of the** $k$ **confidence intervals that actually contains the true parameter** $p=0.1$**, based on your simulation.**

iii. **Compare and comment on the goodness of coverage probability of each of the three confidence intervals, based on your simulation results.**

First, recall that in Exercise 3, we found that the variance-stabilizing transformation (VST)-based confidence intervals for the probability of success parameter $p$ of the binomial distribution have the form:

$$
\Biggl(
\mathrm{sin}^2\biggl(\mathrm{max}\biggl\{\mathrm{arcsin}\sqrt{\hat{p}}- \frac{z_{1-\alpha/2}}{2\sqrt{n}},0\biggr\}\biggr), \;
\mathrm{sin}^2\biggl(\mathrm{min}\biggl\{\mathrm{arcsin}\sqrt{\hat{p}}+ \frac{z_{1-\alpha/2}}{2\sqrt{n}}, \frac{\pi}{2} \biggr\}\biggr)
\Biggr)
$$

```{r}
#| echo: false

k = 100 # number of simulations
p = 0.1 # true parameter value
z = qnorm(0.975) # 0.975 quantile for a 95% CI
```

```{r}
#| echo: false

coverage_calc = function(type, data){
  tally = 0
  if(type == "Wald"){
    for(i in c(1:k)){
      if(data$WaldL[i] < 0.1 & data$WaldU[i] > 0.1){
        tally = tally + 1
      }
    }
    return(tally/k)
  }
  else if(type == "Wilson"){
    for(i in c(1:k)){
      if(data$WilsonL[i] < 0.1 & data$WilsonU[i] > 0.1){
        tally = tally + 1
      }
    }
    return(tally/k)
  }
  else if(type == "VarStab"){
    for(i in c(1:k)){
      if(data$VarStabL[i] < 0.1 & data$VarStabU[i] > 0.1){
        tally = tally + 1
      }
    }
    return(tally/k)
  }
}
```

```{r}
#| echo: false

set.seed(1)

n = 30 # sample size for Part (a)

# Set up dataframe to collect results
data_smalln = array(numeric(), c(k, 7))
colnames(data_smalln) = c("phat", "WaldL", "WaldU", "WilsonL", "WilsonU", "VarStabL", "VarStabU")
data_smalln = as.data.frame(data_smalln)

# Run k simulations and compute p_hat in each
data_smalln$phat = rbinom(k, n, p)/n

# Wald Intervals
data_smalln$WaldL = data_smalln$phat - z*sqrt(data_smalln$phat * (1-data_smalln$phat) / n)
data_smalln$WaldU = data_smalln$phat + z*sqrt(data_smalln$phat * (1-data_smalln$phat) / n)
Wald_coverage_smalln = coverage_calc("Wald", data_smalln)

# Wilson Intervals
data_smalln$WilsonL = (z^2 + 2*n*data_smalln$phat - z*sqrt(z^2 + 4*n*data_smalln$phat*(1-data_smalln$phat))) / (2*(n + z^2))
data_smalln$WilsonU = (z^2 + 2*n*data_smalln$phat + z*sqrt(z^2 + 4*n*data_smalln$phat*(1-data_smalln$phat))) / (2*(n + z^2))
Wilson_coverage_smalln = coverage_calc("Wilson", data_smalln)

# Variance Stabilization Confidence Intervals
data_smalln$VarStabL = sin(asin(sqrt(data_smalln$phat)) - z/(2*sqrt(n)))^2
data_smalln$VarStabU = sin(asin(sqrt(data_smalln$phat)) + z/(2*sqrt(n)))^2
VarStab_coverage_smalln = coverage_calc("VarStab", data_smalln)
```

In the table below, we present the theoretical and empirical (in our specific simulation) coverage probabilities for each type of confidence interval.

|                                  |                Wald                |                Wilson                |                  VST                  |
|-------------------------------|:-------------:|:-------------:|:-------------:|
| Theoretical Coverage Probability |                0.95                |                 0.95                 |                 0.95                  |
| Empirical Coverage Probability   | `r round(Wald_coverage_smalln, 4)` | `r round(Wilson_coverage_smalln, 4)` | `r round(VarStab_coverage_smalln, 4)` |

In short, we would theoretically expect all three confidence interval types to have coverage probabilities of $0.95$. In practice, while the Wilson and VST-based confidence intervals have coverage proportions close to (and even exceeding!) $0.95$, the Wald coverage proportion of $0.88$ falls noticeably short of $0.95$. While the Wald, Wilson, and VST confidence intervals all appeal to the Central Limit Theorem for $\hat{p}=\bar{X}$, and therefore all build in a single approximation (since $n=30$ is not $\infty$), the Wald confidence intervals use an additional approximation for the variance of the distribution of $\hat{p}$. The two stages of approximation involved with constructing Wald intervals explain why this coverage proportion falls short of $0.95$, while the single stage of approximation involved with constructing Wilson and VST intervals allows their coverage proportions to be closer to the theoretical $0.95$.

## Part (b): Large Sample Size

**Repeat the simulation in Part (a) with increased sample size** $n=150$**. Do any of your previous conclusions for** $n=30$ **change? Why?**

```{r}
#| echo: false

set.seed(1)

n = 150 # sample size for Part (b)

# Set up dataframe to collect results
data_largen = array(numeric(), c(k, 7))
colnames(data_largen) = c("phat", "WaldL", "WaldU", "WilsonL", "WilsonU", "VarStabL", "VarStabU")
data_largen = as.data.frame(data_largen)

# Run k simulations and compute p_hat in each
data_largen$phat = rbinom(k, n, p)/n

# Wald Intervals
data_largen$WaldL = data_largen$phat - z*sqrt(data_largen$phat * (1-data_largen$phat) / n)
data_largen$WaldU = data_largen$phat + z*sqrt(data_largen$phat * (1-data_largen$phat) / n)
Wald_coverage_largen = coverage_calc("Wald", data_largen)

# Wilson Intervals
data_largen$WilsonL = (z^2 + 2*n*data_largen$phat - z*sqrt(z^2 + 4*n*data_largen$phat*(1-data_largen$phat))) / (2*(n + z^2))
data_largen$WilsonU = (z^2 + 2*n*data_largen$phat + z*sqrt(z^2 + 4*n*data_largen$phat*(1-data_largen$phat))) / (2*(n + z^2))
Wilson_coverage_largen = coverage_calc("Wilson", data_largen)

# Variance Stabilization Confidence Intervals
data_largen$VarStabL = sin(asin(sqrt(data_largen$phat)) - z/(2*sqrt(n)))^2
data_largen$VarStabU = sin(asin(sqrt(data_largen$phat)) + z/(2*sqrt(n)))^2
VarStab_coverage_largen = coverage_calc("VarStab", data_largen)
```

In the table below, we present the new theoretical and empirical (in our specific simulation) coverage probabilities for each type of confidence interval, using our larger sample size of $n=150$.

|                                  |                Wald                |                Wilson                |                  VST                  |
|------------------------------|:-------------:|:-------------:|:-------------:|
| Theoretical Coverage Probability |                0.95                |                 0.95                 |                 0.95                  |
| Empirical Coverage Probability   | `r round(Wald_coverage_largen, 4)` | `r round(Wilson_coverage_largen, 4)` | `r round(VarStab_coverage_largen, 4)` |

Now, all three types of confidence intervals have coverage proportions meeting (and even exceeding!) the theoretical $0.95$ probability. By substantially increasing the number of trials in each simulation (from $n=30$ to $n=150$), the Wald confidence intervals are now able to overcome the error attributable to their "second stage" of approximation. It is also worth noting that the Wilson coverage proportion has decreased from $0.99$ to $0.98$—with a larger number of trials built into each simulation, it is more difficult to achieve the exceptionally high coverage proportion that occurred by chance before. The VST coverage proportions have stayed the same, at $0.97$, by chance.
